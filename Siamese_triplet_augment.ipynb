{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read me\n",
    "\n",
    "1.运行前请修改路径\n",
    "\n",
    "[1] './data/whale/train.csv' 是train.csv的路径\n",
    "\n",
    "[2] original_image_path = \"./data/whale/train_full/\" 是原始的train image路径\n",
    "\n",
    "[3] image_augment_path = './data/whale/siamese_augment/train_aug' 是增强后的train image存放路径\n",
    "\n",
    "[4] train_csv_path = './data/whale/siamese_augment/train_aug.csv' 是增强后train image中用来作为模型训练的部分数据存放路径\n",
    "\n",
    "[5] test_csv_path = './data/whale/siamese_augment/test_aug.csv' 是增强后train image中用来作为模型validation的部分数据存放路径\n",
    "\n",
    "[6] file_path = os.path.join('./data/whale/siamese_augment', file_path) 用来存放模型的权重\n",
    "\n",
    "[7] test_files = glob.glob(\"./data/whale/test/*.jpg\") 是原始的test image的存放路径\n",
    "\n",
    "[8] sub_csv_path = os.path.join('./data/whale/siamese_augment', sub_csv_path) 是最后的预测结果存放路径\n",
    "\n",
    "\n",
    "2.可调参数\n",
    "\n",
    "[1]batch_size = 8 根据GPU内存大小增加这个值\n",
    "\n",
    "[2]GPU_num = 1 并行计算的GPU个数\n",
    "\n",
    "[3]num_epochs = 3 考虑增加到200以上，代码里增加了early stop和save best result模块，会根据训练结果的好坏提前终止\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, GlobalMaxPooling2D\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.training_utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "# Read data\n",
    "data = pd.read_csv('./data/whale/train.csv')\n",
    "train, test = train_test_split(data, test_size=0.3, shuffle=True, random_state=seed)\n",
    "file_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\n",
    "file_id_mapping_test = {k: v for k, v in zip(test.Image.values, test.Id.values)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_image_path = \"./data/whale/train_full/\"\n",
    "image_augment_path = './data/whale/siamese_augment/train_aug'\n",
    "train_csv_path = './data/whale/siamese_augment/train_aug.csv'\n",
    "test_csv_path = './data/whale/siamese_augment/test_aug.csv'\n",
    "\n",
    "\n",
    "RESIZE_WIDTH, RESIZE_HEIGHT = 256, 256\n",
    "CHANNEL = 3\n",
    "input_shape = (RESIZE_WIDTH, RESIZE_HEIGHT)\n",
    "argument_factor = 6\n",
    "GPU_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_args = dict(rotation_range=10,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "\n",
    "datagen = ImageDataGenerator(**datagen_args)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def read_and_resize(filepath):\n",
    "#   这里不是用的grayscale，而是转成RGB了\n",
    "    im = Image.open((filepath)).convert('RGB')\n",
    "    im = im.resize(input_shape)\n",
    "#   im的shape变成（256， 256， 3）\n",
    "    im_array = np.array(im, dtype=\"uint8\")\n",
    "#   转换成float类型\n",
    "#     return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "    return im_array\n",
    "\n",
    "def data_augment(file_id_mapping, save_image_path=None, save_csv_path=None):\n",
    "    image_names = []\n",
    "    id_names = []\n",
    "#     i = 0\n",
    "    for image_name, id_name in file_id_mapping.iteritems():\n",
    "        image_prefix = image_name.split('.')[0]\n",
    "        image_resized = read_and_resize(os.path.join(original_image_path, image_name))\n",
    "        image_names.append(image_prefix + '_0.jpg')\n",
    "        id_names.append(id_name)\n",
    "        im = Image.fromarray(image_resized)\n",
    "        im.convert('RGB').save(os.path.join(save_image_path, image_prefix + '_0.jpg')) #bug of PIL ? cannot save grayscale\n",
    "        \n",
    "#         image_resized = image_resized.reshape(input_shape+(CHANNEL,))\n",
    "        for j in range(1, argument_factor):\n",
    "            augmented = datagen.random_transform(image_resized)\n",
    "            image_names.append(image_prefix + '_' + str(j) + '.jpg')\n",
    "            id_names.append(id_name)\n",
    "            im = Image.fromarray(augmented)\n",
    "            im.convert('RGB').save(os.path.join(save_image_path, image_prefix + '_' + str(j) + '.jpg'))\n",
    "        \n",
    "#         i += 1\n",
    "#         if i > 2:\n",
    "#             break\n",
    "    \n",
    "    file_id_df = pd.DataFrame(data={'Image':image_names, 'Id':id_names})\n",
    "    file_id_df.to_csv(save_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imm = read_and_resize('./data/whale/train_full/11da3702.jpg')\n",
    "# print imm.shape\n",
    "# im = Image.fromarray(imm)\n",
    "# im.convert('RGB').save('./data/whale/11da3702_test.jpg')\n",
    "# im = Image.open(('./data/whale/11da3702_test.jpg'))\n",
    "# im_array = np.array(im, dtype=\"uint8\")\n",
    "# print im_array.shape\n",
    "# print im_array[100:115, 128, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augment train images\n",
    "data_augment(file_id_mapping_train, save_image_path=image_augment_path, save_csv_path=train_csv_path)\n",
    "# augment test images\n",
    "data_augment(file_id_mapping_test, save_image_path=image_augment_path, save_csv_path=test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define batch generator & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sample_gen(object):\n",
    "    def __init__(self, file_class_mapping, other_class = \"new_whale\"):\n",
    "        self.file_class_mapping= file_class_mapping\n",
    "        self.class_to_list_files = defaultdict(list)\n",
    "        self.list_other_class = []\n",
    "        self.list_all_files = list(file_class_mapping.keys())\n",
    "        self.range_all_files = list(range(len(self.list_all_files)))\n",
    "\n",
    "        for file, class_ in file_class_mapping.items():\n",
    "            if class_ == other_class:\n",
    "                self.list_other_class.append(file)\n",
    "            else:\n",
    "                self.class_to_list_files[class_].append(file)\n",
    "\n",
    "#       注意这里的class id有重复\n",
    "        self.list_classes = list(set(self.file_class_mapping.values()))\n",
    "        self.range_list_classes= range(len(self.list_classes))\n",
    "#       每个class（Id）的比重，相当于直方图  \n",
    "        self.class_weight = np.array([len(self.class_to_list_files[class_]) for class_ in self.list_classes]) * 1.0\n",
    "#         self.class_weight = self.class_weight/np.sum(self.class_weight)\n",
    "        \n",
    "        self.class_weight /= self.class_weight.sum()\n",
    "        print \"sum=\", self.class_weight.sum()\n",
    "\n",
    "#   这个函数只是返回一个triplet样例\n",
    "    def get_sample(self):\n",
    "#       按class id比重抽取一个样本\n",
    "        class_idx = np.random.choice(self.range_list_classes, 1, p=self.class_weight)[0]\n",
    "#       对这种class id的，抽取两个样本images (如果某个class只有一个样本，那么返回的是两个一样的image)\n",
    "        examples_class_idx = np.random.choice(range(len(self.class_to_list_files[self.list_classes[class_idx]])), 2)\n",
    "#       注意这两个样本属于同一个class\n",
    "        positive_example_1, positive_example_2 = \\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[0]],\\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[1]]\n",
    "\n",
    "#       提取一个跟positive_example_1不同class的样本\n",
    "        negative_example = None\n",
    "        while negative_example is None or self.file_class_mapping[negative_example] == \\\n",
    "                self.file_class_mapping[positive_example_1]:\n",
    "            negative_example_idx = np.random.choice(self.range_all_files, 1)[0]\n",
    "            negative_example = self.list_all_files[negative_example_idx]\n",
    "        return positive_example_1, negative_example, positive_example_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# input_shape = (256, 256)\n",
    "base_path = image_augment_path\n",
    "\n",
    "# 就是返回了y_pred的平均值\n",
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "# Bayesian Personalized Ranking loss\n",
    "def bpr_triplet_loss(X):\n",
    "\n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "    # BPR loss\n",
    "    loss = 1.0 - K.sigmoid(\n",
    "        K.sum(user_latent * positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(user_latent * negative_item_latent, axis=-1, keepdims=True))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_base_model():\n",
    "    latent_dim = 50\n",
    "#   include_top：whether to include the fully-connected layer at the top of the network.\n",
    "#   输入是grayscale , 256, 256 ,1, 因为include_top是false，这里必须显示指明input_shape\n",
    "    base_model = ResNet50(weights = 'imagenet',include_top=False, input_shape=input_shape+(CHANNEL,)) # use weights='imagenet' locally\n",
    "\n",
    "    # for layer in base_model.layers:\n",
    "    #     layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(latent_dim)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_1)\n",
    "#   相当于对这50长度的vector，每个元素取平方，方便后面的距离计算\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model\n",
    "\n",
    "def build_model():\n",
    "    base_model = get_base_model()\n",
    "#   input结构变成(256, 256, 3)\n",
    "    positive_example_1 = Input(input_shape+(CHANNEL,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(CHANNEL,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(CHANNEL,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "#   用triplet loss的方式对三个embedding进行merge,输出是一个sigmoid\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "    \n",
    "    # check to see if we are compiling using just a single GPU\n",
    "    if GPU_num <= 1:\n",
    "        print(\"[INFO] training with 1 GPU...\")\n",
    "        model = Model(input=[positive_example_1, negative_example, positive_example_2],output=loss)\n",
    "    # otherwise, we are compiling using multiple GPUs\n",
    "    else:\n",
    "        print(\"[INFO] training with {} GPUs...\".format(GPU_num))\n",
    "\n",
    "        # we'll store a copy of the model on *every* GPU and then combine\n",
    "        # the results from the gradient updates on the CPU\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            # initialize the model\n",
    "            model = Model(input=[positive_example_1, negative_example, positive_example_2],output=loss)\n",
    "\n",
    "        # make the model parallel\n",
    "        model = multi_gpu_model(model, gpus=GPU_num)    \n",
    "        \n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_name = \"triplet_model\"\n",
    "\n",
    "file_path = model_name + \"weights.best.hdf5\"\n",
    "file_path = os.path.join('./data/whale/siamese_augment', file_path)\n",
    "\n",
    "\n",
    "\n",
    "def build_inference_model(weight_path=file_path):\n",
    "    base_model = get_base_model()\n",
    "\n",
    "    positive_example_1 = Input(input_shape+(CHANNEL,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(CHANNEL,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(CHANNEL,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "#   导入前面训练出来的权重\n",
    "    model.load_weights(weight_path)\n",
    "\n",
    "#   base model只包含了把input转为embedding的过程，没有包含后面的triplet loss部分\n",
    "    inference_model = Model(base_model.get_input_at(0), output=base_model.get_output_at(0))\n",
    "    inference_model.compile(loss=\"mse\", optimizer=Adam(0.000001))\n",
    "    print(inference_model.summary())\n",
    "\n",
    "    return inference_model\n",
    "\n",
    "def read_and_normalize(filepath):\n",
    "    im = Image.open((filepath))\n",
    "    im_array = np.array(im, dtype=\"uint8\")[..., ::-1] \n",
    "#     im_array = im_array.reshape(input_shape+(CHANNEL,))\n",
    "#   转换成float类型\n",
    "    return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "\n",
    "# # 进行小概率的augment\n",
    "# def augment(im_array):\n",
    "#     if np.random.uniform(0, 1) > 0.9:\n",
    "# #       fliplr只对第1维度column进行flip\n",
    "#         im_array = np.fliplr(im_array)\n",
    "#     return im_array\n",
    "\n",
    "# 这个函数返回一个generator\n",
    "batch_size = 8\n",
    "\n",
    "def gen(triplet_gen):\n",
    "    while True:\n",
    "        list_positive_examples_1 = []\n",
    "        list_negative_examples = []\n",
    "        list_positive_examples_2 = []\n",
    "\n",
    "#       会有重复抽样\n",
    "        for i in range(batch_size):\n",
    "            positive_example_1, negative_example, positive_example_2 = triplet_gen.get_sample()\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = read_and_normalize(os.path.join(base_path,positive_example_1)), \\\n",
    "                                                                       read_and_normalize(os.path.join(base_path, negative_example)), \\\n",
    "                                                                       read_and_normalize(os.path.join(base_path, positive_example_2))\n",
    "\n",
    "\n",
    "            list_positive_examples_1.append(positive_example_1_img)\n",
    "            list_negative_examples.append(negative_example_img)\n",
    "            list_positive_examples_2.append(positive_example_2_img)\n",
    "\n",
    "        list_positive_examples_1 = np.array(list_positive_examples_1)\n",
    "        list_negative_examples = np.array(list_negative_examples)\n",
    "        list_positive_examples_2 = np.array(list_positive_examples_2)\n",
    "        \n",
    "#       利用yield，返回一个generator, 并且call on the fly (通过yield + while True)，节省内存\n",
    "#       注意配合model.fit_generator使用的generator返回值必须是（input, target），所以后面的np.ones(batch_size)相当于target (即label)\n",
    "#       只不过在这个模型里面这个target没有被用上而已\n",
    "#       最后注意每次yield返回一个batch的samples\n",
    "        yield [list_positive_examples_1, list_negative_examples, list_positive_examples_2], np.ones(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum= 1.0000000000000002\n",
      "sum= 1.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "\n",
    "# Read data\n",
    "train = pd.read_csv(train_csv_path)\n",
    "test = pd.read_csv(test_csv_path)\n",
    "# train, test = train_test_split(data, test_size=0.3, shuffle=True, random_state=1337)\n",
    "#把image作为key，id作为value\n",
    "file_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\n",
    "file_id_mapping_test = {k: v for k, v in zip(test.Image.values, test.Id.values)}\n",
    "train_gen = sample_gen(file_id_mapping_train)\n",
    "test_gen = sample_gen(file_id_mapping_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 161s 2us/step\n",
      "94666752/94653016 [==============================] - 161s 2us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:99: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:104: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"lo..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training with 1 GPU...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "positive_example_1 (InputLayer) (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_example (InputLayer)   (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_example_2 (InputLayer) (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Model)              (None, 50)           23690162    positive_example_1[0][0]         \n",
      "                                                                 negative_example[0][0]           \n",
      "                                                                 positive_example_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "loss (Merge)                    (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "                                                                 base_model[3][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,690,162\n",
      "Trainable params: 23,637,042\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      " - 530s - loss: 0.4654 - val_loss: 0.3892\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38917, saving model to ./data/whale/siamese_augment/triplet_modelweights.best.hdf5\n",
      "Epoch 2/300\n",
      " - 501s - loss: 0.4496 - val_loss: 0.3560\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38917 to 0.35603, saving model to ./data/whale/siamese_augment/triplet_modelweights.best.hdf5\n",
      "Epoch 3/300\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test triplets\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "\n",
    "#model.load_weights(file_path)\n",
    "\n",
    "# 根据monitor的值即loss，保存loss最小(min)时的model (best model)\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=25)\n",
    "\n",
    "callbacks_list = [checkpoint, early]  # early\n",
    "\n",
    "# Trains the model on data generated batch-by-batch by a Python generator\n",
    "# 这种模式，generate bath on the fly，可以节省很多memory，因而可以使用更大的batch size\n",
    "history = model.fit_generator(gen(train_gen), validation_data=gen(test_gen), epochs=num_epochs, verbose=2, workers=4, use_multiprocessing=True,\n",
    "                              callbacks=callbacks_list, steps_per_epoch=1000, validation_steps=100)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_resize_normalize(filepath):\n",
    "# #   这里不是用的grayscale，而是转成RGB了\n",
    "#     im = Image.open((filepath)).convert('L')\n",
    "# #     im = im.resize(input_shape)\n",
    "# #   im的shape变成（256， 256， 3）\n",
    "#     im_array = np.array(im, dtype=\"uint8\")\n",
    "#     print im_array.shape\n",
    "# #     im_array = im_array.reshape(input_shape+(CHANNEL,))\n",
    "# #   转换成float类型\n",
    "#     return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "\n",
    "# imm = read_resize_normalize('./data/whale/train_full/11da3702.jpg')\n",
    "# print imm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"triplet_loss\"\n",
    "\n",
    "def read_resize_normalize(filepath):\n",
    "#   这里不是用的grayscale，而是转成RGB了\n",
    "    im = Image.open((filepath)).convert('RGB')\n",
    "    im = im.resize(input_shape)\n",
    "#   im的shape变成（256， 256， 3）\n",
    "    im_array = np.array(im, dtype=\"uint8\")[..., ::-1]\n",
    "#     im_array = im_array.reshape(input_shape+(CHANNEL,))\n",
    "#   转换成float类型\n",
    "    return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "\n",
    "\n",
    "def data_generator(fpaths, batch=16):\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        img = read_resize_normalize(path)\n",
    "        imgs.append(img)\n",
    "#       获取image的名字\n",
    "        fnames.append(os.path.basename(path))\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "#           每次yield返回一个batch的samples\n",
    "            yield fnames, imgs\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        yield fnames, imgs\n",
    "    raise StopIteration()\n",
    "\n",
    "data = pd.read_csv('./data/whale/train.csv')\n",
    "\n",
    "file_id_mapping = {k: v for k, v in zip(data.Image.values, data.Id.values)}\n",
    "\n",
    "inference_model = build_inference_model()\n",
    "\n",
    "# 文件名匹配，返回一个list包含所有这个后缀的文件path\n",
    "train_files = glob.glob(\"./data/whale/train_full/*.jpg\")\n",
    "test_files = glob.glob(\"./data/whale/test/*.jpg\")\n",
    "\n",
    "train_preds = []\n",
    "train_file_names = []\n",
    "i = 1\n",
    "# 每个imgs里面包含的是一个batch的samples\n",
    "for fnames, imgs in data_generator(train_files, batch=32):\n",
    "#     print(i*32/len(train_files)*100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "#   将一个batch的images转换成embeddings，然后转成list\n",
    "    predicts = predicts.tolist()\n",
    "    train_preds += predicts\n",
    "    train_file_names += fnames\n",
    "\n",
    "#  得到了所有train images的embeddings\n",
    "train_preds = np.array(train_preds)\n",
    "\n",
    "test_preds = []\n",
    "test_file_names = []\n",
    "i = 1\n",
    "for fnames, imgs in data_generator(test_files, batch=32):\n",
    "#     print(i * 32 / len(test_files) * 100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "    predicts = predicts.tolist()\n",
    "    test_preds += predicts\n",
    "    test_file_names += fnames\n",
    "\n",
    "#  得到了所有test images的embeddings\n",
    "test_preds = np.array(test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这里用欧式距离判断class id，并且选取了6个neighbors\n",
    "neigh = NearestNeighbors(n_neighbors=6)\n",
    "neigh.fit(train_preds)\n",
    "#distances, neighbors = neigh.kneighbors(train_preds)\n",
    "\n",
    "#print(distances, neighbors)\n",
    "\n",
    "# 对每个test样本，返回最近的六个embeddings,注意neighbors_test是train_preds里面样本的Index，而非样本本身\n",
    "distances_test, neighbors_test = neigh.kneighbors(test_preds)\n",
    "\n",
    "distances_test, neighbors_test = distances_test.tolist(), neighbors_test.tolist()\n",
    "\n",
    "preds_str = []\n",
    "\n",
    "for filepath, distance, neighbour_ in zip(test_file_names, distances_test, neighbors_test):\n",
    "    sample_result = []\n",
    "    sample_classes = []\n",
    "    for d, n in zip(distance, neighbour_):\n",
    "        train_file = train_files[n].split(os.sep)[-1]\n",
    "        class_train = file_id_mapping[train_file]\n",
    "        sample_classes.append(class_train)\n",
    "        sample_result.append((class_train, d))\n",
    "\n",
    "    if \"new_whale\" not in sample_classes:\n",
    "        sample_result.append((\"new_whale\", 0.1))#new_whale有大概率出现，距离设置为0.1\n",
    "    sample_result.sort(key=lambda x: x[1])\n",
    "    sample_result = sample_result[:5] #取前五个距离最小的预测值\n",
    "    preds_str.append(\" \".join([x[0] for x in sample_result]))\n",
    "\n",
    "df = pd.DataFrame(preds_str, columns=[\"Id\"])\n",
    "df['Image'] = [x.split(os.sep)[-1] for x in test_file_names]\n",
    "sub_csv_path = \"sub_%s.csv\"%model_name\n",
    "sub_csv_path = os.path.join('./data/whale/siamese_augment', sub_csv_path)\n",
    "df.to_csv(sub_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
