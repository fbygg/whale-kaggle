{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read me\n",
    "\n",
    "1.运行前请修改路径\n",
    "\n",
    "[1] './data/whale/train.csv' 是train.csv的路径\n",
    "\n",
    "[2] original_image_path = \"./data/whale/train_full/\" 是原始的train image路径\n",
    "\n",
    "[3] image_augment_path = './data/whale/siamese_augment/train_aug' 是增强后的train image存放路径\n",
    "\n",
    "[4] train_csv_path = './data/whale/siamese_augment/train_aug.csv' 是增强后train image中用来作为模型训练的部分数据存放路径\n",
    "\n",
    "[5] test_csv_path = './data/whale/siamese_augment/test_aug.csv' 是增强后train image中用来作为模型validation的部分数据存放路径\n",
    "\n",
    "[6] file_path = os.path.join('./data/whale/siamese_augment', file_path) 用来存放模型的权重\n",
    "\n",
    "[7] test_files = glob.glob(\"./data/whale/test/*.jpg\") 是原始的test image的存放路径\n",
    "\n",
    "[8] sub_csv_path = os.path.join('./data/whale/siamese_augment', sub_csv_path) 是最后的预测结果存放路径\n",
    "\n",
    "\n",
    "2.可调参数\n",
    "\n",
    "[1]batch_size = 8 根据GPU内存大小增加这个值\n",
    "\n",
    "[2]num_epochs = 3 考虑增加到200以上，代码里增加了early stop和save best result模块，会根据训练结果的好坏提前终止\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, GlobalMaxPooling2D\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "# Read data\n",
    "data = pd.read_csv('./data/whale/train.csv')\n",
    "train, test = train_test_split(data, test_size=0.3, shuffle=True, random_state=seed)\n",
    "file_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\n",
    "file_id_mapping_test = {k: v for k, v in zip(test.Image.values, test.Id.values)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_image_path = \"./data/whale/train_full/\"\n",
    "image_augment_path = './data/whale/siamese_augment/train_aug'\n",
    "train_csv_path = './data/whale/siamese_augment/train_aug.csv'\n",
    "test_csv_path = './data/whale/siamese_augment/test_aug.csv'\n",
    "\n",
    "\n",
    "RESIZE_WIDTH, RESIZE_HEIGHT = 256, 256\n",
    "CHANNEL = 1\n",
    "input_shape = (RESIZE_WIDTH, RESIZE_HEIGHT)\n",
    "argument_factor = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_args = dict(rotation_range=10,\n",
    "                    width_shift_range=0.15,\n",
    "                    height_shift_range=0.15,\n",
    "                    shear_range=0.15,\n",
    "                    zoom_range=0.15,\n",
    "                    horizontal_flip=False)\n",
    "\n",
    "datagen = ImageDataGenerator(**datagen_args)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def read_and_resize(filepath):\n",
    "#   这里不是用的grayscale，而是转成RGB了\n",
    "    im = Image.open((filepath)).convert('L')\n",
    "    im = im.resize(input_shape)\n",
    "#   im的shape变成（256， 256， 3）\n",
    "    im_array = np.array(im, dtype=\"uint8\")\n",
    "#   转换成float类型\n",
    "#     return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "    return im_array\n",
    "\n",
    "def data_augment(file_id_mapping, save_image_path=None, save_csv_path=None):\n",
    "    image_names = []\n",
    "    id_names = []\n",
    "#     i = 0\n",
    "    for image_name, id_name in file_id_mapping.iteritems():\n",
    "        image_prefix = image_name.split('.')[0]\n",
    "        image_resized = read_and_resize(os.path.join(original_image_path, image_name))\n",
    "        image_names.append(image_prefix + '_0.jpg')\n",
    "        id_names.append(id_name)\n",
    "        im = Image.fromarray(image_resized)\n",
    "        im.convert('RGB').save(os.path.join(save_image_path, image_prefix + '_0.jpg'))\n",
    "        \n",
    "        for j in range(1, argument_factor):\n",
    "            augmented = datagen.random_transform(image_resized)\n",
    "            image_names.append(image_prefix + '_' + str(j) + '.jpg')\n",
    "            id_names.append(id_name)\n",
    "            im = Image.fromarray(augmented)\n",
    "            im.convert('RGB').save(os.path.join(save_image_path, image_prefix + '_' + str(j) + '.jpg'))\n",
    "        \n",
    "#         i += 1\n",
    "#         if i > 2:\n",
    "#             break\n",
    "    \n",
    "    file_id_df = pd.DataFrame(data={'Image':image_names, 'Id':id_names})\n",
    "    file_id_df.to_csv(save_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augment train images\n",
    "data_augment(file_id_mapping_train, save_image_path=image_augment_path, save_csv_path=train_csv_path)\n",
    "# augment test images\n",
    "data_augment(file_id_mapping_test, save_image_path=image_augment_path, save_csv_path=test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define batch generator & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sample_gen(object):\n",
    "    def __init__(self, file_class_mapping, other_class = \"new_whale\"):\n",
    "        self.file_class_mapping= file_class_mapping\n",
    "        self.class_to_list_files = defaultdict(list)\n",
    "        self.list_other_class = []\n",
    "        self.list_all_files = list(file_class_mapping.keys())\n",
    "        self.range_all_files = list(range(len(self.list_all_files)))\n",
    "\n",
    "        for file, class_ in file_class_mapping.items():\n",
    "            if class_ == other_class:\n",
    "                self.list_other_class.append(file)\n",
    "            else:\n",
    "                self.class_to_list_files[class_].append(file)\n",
    "\n",
    "#       注意这里的class id有重复\n",
    "        self.list_classes = list(set(self.file_class_mapping.values()))\n",
    "        self.range_list_classes= range(len(self.list_classes))\n",
    "#       每个class（Id）的比重，相当于直方图  \n",
    "        self.class_weight = np.array([len(self.class_to_list_files[class_]) for class_ in self.list_classes]) * 1.0\n",
    "#         self.class_weight = self.class_weight/np.sum(self.class_weight)\n",
    "        \n",
    "        self.class_weight /= self.class_weight.sum()\n",
    "        print \"sum=\", self.class_weight.sum()\n",
    "\n",
    "#   这个函数只是返回一个triplet样例\n",
    "    def get_sample(self):\n",
    "#       按class id比重抽取一个样本\n",
    "        class_idx = np.random.choice(self.range_list_classes, 1, p=self.class_weight)[0]\n",
    "#       对这种class id的，抽取两个样本images (如果某个class只有一个样本，那么返回的是两个一样的image)\n",
    "        examples_class_idx = np.random.choice(range(len(self.class_to_list_files[self.list_classes[class_idx]])), 2)\n",
    "#       注意这两个样本属于同一个class\n",
    "        positive_example_1, positive_example_2 = \\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[0]],\\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[1]]\n",
    "\n",
    "#       提取一个跟positive_example_1不同class的样本\n",
    "        negative_example = None\n",
    "        while negative_example is None or self.file_class_mapping[negative_example] == \\\n",
    "                self.file_class_mapping[positive_example_1]:\n",
    "            negative_example_idx = np.random.choice(self.range_all_files, 1)[0]\n",
    "            negative_example = self.list_all_files[negative_example_idx]\n",
    "        return positive_example_1, negative_example, positive_example_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# input_shape = (256, 256)\n",
    "base_path = image_augment_path\n",
    "\n",
    "# 就是返回了y_pred的平均值\n",
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "# Bayesian Personalized Ranking loss\n",
    "def bpr_triplet_loss(X):\n",
    "\n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "    # BPR loss\n",
    "    loss = 1.0 - K.sigmoid(\n",
    "        K.sum(user_latent * positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(user_latent * negative_item_latent, axis=-1, keepdims=True))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_base_model():\n",
    "    latent_dim = 50\n",
    "#   include_top：whether to include the fully-connected layer at the top of the network.\n",
    "#   输入是grayscale , 256, 256 ,1, 因为include_top是false，这里必须显示指明input_shape\n",
    "    base_model = ResNet50(weights = None,include_top=False, input_shape=input_shape+(CHANNEL,)) # use weights='imagenet' locally\n",
    "\n",
    "    # for layer in base_model.layers:\n",
    "    #     layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(latent_dim)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_1)\n",
    "#   相当于对这50长度的vector，每个元素取平方，方便后面的距离计算\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model\n",
    "\n",
    "def build_model():\n",
    "    base_model = get_base_model()\n",
    "#   input结构变成(256, 256, 3)\n",
    "    positive_example_1 = Input(input_shape+(CHANNEL,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(CHANNEL,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(CHANNEL,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "#   用triplet loss的方式对三个embedding进行merge,输出是一个sigmoid\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_name = \"triplet_model\"\n",
    "\n",
    "file_path = model_name + \"weights.best.hdf5\"\n",
    "file_path = os.path.join('./data/whale/siamese_augment', file_path)\n",
    "\n",
    "\n",
    "\n",
    "def build_inference_model(weight_path=file_path):\n",
    "    base_model = get_base_model()\n",
    "\n",
    "    positive_example_1 = Input(input_shape+(CHANNEL,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(CHANNEL,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(CHANNEL,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "#   导入前面训练出来的权重\n",
    "    model.load_weights(weight_path)\n",
    "\n",
    "#   base model只包含了把input转为embedding的过程，没有包含后面的triplet loss部分\n",
    "    inference_model = Model(base_model.get_input_at(0), output=base_model.get_output_at(0))\n",
    "    inference_model.compile(loss=\"mse\", optimizer=Adam(0.000001))\n",
    "    print(inference_model.summary())\n",
    "\n",
    "    return inference_model\n",
    "\n",
    "def read_and_normalize(filepath):\n",
    "#   这里不是用的grayscale，而是转成RGB了\n",
    "    im = Image.open((filepath))\n",
    "#     im = im.resize(input_shape)\n",
    "#   im的shape变成（256， 256， 3）\n",
    "    im_array = np.array(im, dtype=\"uint8\")\n",
    "    im_array = im_array.reshape(input_shape+(CHANNEL,))\n",
    "#   转换成float类型\n",
    "    return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "\n",
    "# # 进行小概率的augment\n",
    "# def augment(im_array):\n",
    "#     if np.random.uniform(0, 1) > 0.9:\n",
    "# #       fliplr只对第1维度column进行flip\n",
    "#         im_array = np.fliplr(im_array)\n",
    "#     return im_array\n",
    "\n",
    "# 这个函数返回一个generator\n",
    "batch_size = 8\n",
    "\n",
    "def gen(triplet_gen):\n",
    "    while True:\n",
    "        list_positive_examples_1 = []\n",
    "        list_negative_examples = []\n",
    "        list_positive_examples_2 = []\n",
    "\n",
    "#       会有重复抽样\n",
    "        for i in range(batch_size):\n",
    "            positive_example_1, negative_example, positive_example_2 = triplet_gen.get_sample()\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = read_and_normalize(os.path.join(base_path,positive_example_1)), \\\n",
    "                                                                       read_and_normalize(os.path.join(base_path, negative_example)), \\\n",
    "                                                                       read_and_normalize(os.path.join(base_path, positive_example_2))\n",
    "\n",
    "\n",
    "            list_positive_examples_1.append(positive_example_1_img)\n",
    "            list_negative_examples.append(negative_example_img)\n",
    "            list_positive_examples_2.append(positive_example_2_img)\n",
    "\n",
    "        list_positive_examples_1 = np.array(list_positive_examples_1)\n",
    "        list_negative_examples = np.array(list_negative_examples)\n",
    "        list_positive_examples_2 = np.array(list_positive_examples_2)\n",
    "        \n",
    "#       利用yield，返回一个generator, 并且call on the fly (通过yield + while True)，节省内存\n",
    "#       注意配合model.fit_generator使用的generator返回值必须是（input, target），所以后面的np.ones(batch_size)相当于target (即label)\n",
    "#       只不过在这个模型里面这个target没有被用上而已\n",
    "#       最后注意每次yield返回一个batch的samples\n",
    "        yield [list_positive_examples_1, list_negative_examples, list_positive_examples_2], np.ones(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum= 1.0000000000000002\n",
      "sum= 1.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "# Read data\n",
    "train = pd.read_csv(train_csv_path)\n",
    "test = pd.read_csv(test_csv_path)\n",
    "# train, test = train_test_split(data, test_size=0.3, shuffle=True, random_state=1337)\n",
    "#把image作为key，id作为value\n",
    "file_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\n",
    "file_id_mapping_test = {k: v for k, v in zip(test.Image.values, test.Id.values)}\n",
    "train_gen = sample_gen(file_id_mapping_train)\n",
    "test_gen = sample_gen(file_id_mapping_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:99: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:103: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"lo..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "positive_example_1 (InputLayer) (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_example (InputLayer)   (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_example_2 (InputLayer) (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Model)              (None, 50)           23683890    positive_example_1[0][0]         \n",
      "                                                                 negative_example[0][0]           \n",
      "                                                                 positive_example_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "loss (Merge)                    (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "                                                                 base_model[3][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,683,890\n",
      "Trainable params: 23,630,770\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      " - 501s - loss: 0.4642 - val_loss: 0.4090\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40904, saving model to ./data/whale/siamese_augment/triplet_modelweights.best.hdf5\n",
      "Epoch 2/3\n",
      " - 463s - loss: 0.4333 - val_loss: 0.3888\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40904 to 0.38880, saving model to ./data/whale/siamese_augment/triplet_modelweights.best.hdf5\n",
      "Epoch 3/3\n",
      " - 462s - loss: 0.4240 - val_loss: 0.3722\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38880 to 0.37218, saving model to ./data/whale/siamese_augment/triplet_modelweights.best.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test triplets\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "\n",
    "#model.load_weights(file_path)\n",
    "\n",
    "# 根据monitor的值即loss，保存loss最小(min)时的model (best model)\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "\n",
    "callbacks_list = [checkpoint, early]  # early\n",
    "\n",
    "# Trains the model on data generated batch-by-batch by a Python generator\n",
    "# 这种模式，generate bath on the fly，可以节省很多memory，因而可以使用更大的batch size\n",
    "history = model.fit_generator(gen(train_gen), validation_data=gen(test_gen), epochs=num_epochs, verbose=2, workers=1, use_multiprocessing=False,\n",
    "                              callbacks=callbacks_list, steps_per_epoch=1000, validation_steps=100)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# imm = read_and_normalize('./data/whale/siamese_augment/train_aug/11da3702_2.jpg')\n",
    "# print imm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 1010)\n"
     ]
    }
   ],
   "source": [
    "# def read_resize_normalize(filepath):\n",
    "# #   这里不是用的grayscale，而是转成RGB了\n",
    "#     im = Image.open((filepath)).convert('L')\n",
    "# #     im = im.resize(input_shape)\n",
    "# #   im的shape变成（256， 256， 3）\n",
    "#     im_array = np.array(im, dtype=\"uint8\")\n",
    "#     print im_array.shape\n",
    "# #     im_array = im_array.reshape(input_shape+(CHANNEL,))\n",
    "# #   转换成float类型\n",
    "#     return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "\n",
    "# imm = read_resize_normalize('./data/whale/train_full/11da3702.jpg')\n",
    "# print imm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:133: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:137: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"lo..., inputs=[<tf.Tenso...)`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:144: UserWarning: Update your `Model` call to the Keras 2 API: `Model(Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 1)  0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 3200        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 128, 128, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 63, 63, 64)   0           activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 63, 63, 64)   4160        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 63, 63, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 63, 63, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 63, 63, 64)   36928       activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 63, 63, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 63, 63, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 63, 63, 256)  16640       activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 63, 63, 256)  16640       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 63, 63, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 63, 63, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 63, 63, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 63, 63, 256)  0           add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 63, 63, 64)   16448       activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 63, 63, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 63, 63, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 63, 63, 64)   36928       activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 63, 63, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 63, 63, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 63, 63, 256)  16640       activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 63, 63, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 63, 63, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 63, 63, 256)  0           add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 63, 63, 64)   16448       activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 63, 63, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 63, 63, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 63, 63, 64)   36928       activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 63, 63, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 63, 63, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 63, 63, 256)  16640       activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 63, 63, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_115 (Add)                   (None, 63, 63, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 63, 63, 256)  0           add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32896       activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 32, 32, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 32, 32, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131584      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_116 (Add)                   (None, 32, 32, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 32, 32, 512)  0           add_116[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 32, 32, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 32, 32, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_117 (Add)                   (None, 32, 32, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 32, 32, 512)  0           add_117[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 32, 32, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 32, 32, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_118 (Add)                   (None, 32, 32, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 32, 32, 512)  0           add_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 32, 32, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 32, 32, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_119 (Add)                   (None, 32, 32, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 32, 32, 512)  0           add_119[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131328      activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 16, 16, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 16, 16, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 525312      activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_120 (Add)                   (None, 16, 16, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 16, 16, 1024) 0           add_120[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 16, 16, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 16, 16, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_121 (Add)                   (None, 16, 16, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 16, 16, 1024) 0           add_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 16, 16, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 16, 16, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_122 (Add)                   (None, 16, 16, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 16, 16, 1024) 0           add_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 16, 16, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 16, 16, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_123 (Add)                   (None, 16, 16, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 16, 16, 1024) 0           add_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 16, 16, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 16, 16, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_124 (Add)                   (None, 16, 16, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 16, 16, 1024) 0           add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 16, 16, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 16, 16, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_125 (Add)                   (None, 16, 16, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 16, 16, 1024) 0           add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524800      activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 8, 8, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 8, 8, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2099200     activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_126 (Add)                   (None, 8, 8, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 8, 8, 2048)   0           add_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 8, 8, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 8, 8, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_127 (Add)                   (None, 8, 8, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 8, 8, 2048)   0           add_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 8, 8, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 8, 8, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_128 (Add)                   (None, 8, 8, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 8, 8, 2048)   0           add_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_8 (GlobalM (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 2048)         0           global_max_pooling2d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 50)           102450      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 50)           0           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,683,890\n",
      "Trainable params: 23,630,770\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = \"triplet_loss\"\n",
    "\n",
    "def read_resize_normalize(filepath):\n",
    "#   这里不是用的grayscale，而是转成RGB了\n",
    "    im = Image.open((filepath)).convert('L')\n",
    "    im = im.resize(input_shape)\n",
    "#   im的shape变成（256， 256， 3）\n",
    "    im_array = np.array(im, dtype=\"uint8\")\n",
    "    im_array = im_array.reshape(input_shape+(CHANNEL,))\n",
    "#   转换成float类型\n",
    "    return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "\n",
    "\n",
    "def data_generator(fpaths, batch=16):\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        img = read_resize_normalize(path)\n",
    "        imgs.append(img)\n",
    "#       获取image的名字\n",
    "        fnames.append(os.path.basename(path))\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "#           每次yield返回一个batch的samples\n",
    "            yield fnames, imgs\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        yield fnames, imgs\n",
    "    raise StopIteration()\n",
    "\n",
    "data = pd.read_csv('./data/whale/train.csv')\n",
    "\n",
    "file_id_mapping = {k: v for k, v in zip(data.Image.values, data.Id.values)}\n",
    "\n",
    "inference_model = build_inference_model()\n",
    "\n",
    "# 文件名匹配，返回一个list包含所有这个后缀的文件path\n",
    "train_files = glob.glob(\"./data/whale/train_full/*.jpg\")\n",
    "test_files = glob.glob(\"./data/whale/test/*.jpg\")\n",
    "\n",
    "train_preds = []\n",
    "train_file_names = []\n",
    "i = 1\n",
    "# 每个imgs里面包含的是一个batch的samples\n",
    "for fnames, imgs in data_generator(train_files, batch=32):\n",
    "#     print(i*32/len(train_files)*100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "#   将一个batch的images转换成embeddings，然后转成list\n",
    "    predicts = predicts.tolist()\n",
    "    train_preds += predicts\n",
    "    train_file_names += fnames\n",
    "\n",
    "#  得到了所有train images的embeddings\n",
    "train_preds = np.array(train_preds)\n",
    "\n",
    "test_preds = []\n",
    "test_file_names = []\n",
    "i = 1\n",
    "for fnames, imgs in data_generator(test_files, batch=32):\n",
    "#     print(i * 32 / len(test_files) * 100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "    predicts = predicts.tolist()\n",
    "    test_preds += predicts\n",
    "    test_file_names += fnames\n",
    "\n",
    "#  得到了所有test images的embeddings\n",
    "test_preds = np.array(test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里用欧式距离判断class id，并且选取了6个neighbors\n",
    "neigh = NearestNeighbors(n_neighbors=6)\n",
    "neigh.fit(train_preds)\n",
    "#distances, neighbors = neigh.kneighbors(train_preds)\n",
    "\n",
    "#print(distances, neighbors)\n",
    "\n",
    "# 对每个test样本，返回最近的六个embeddings,注意neighbors_test是train_preds里面样本的Index，而非样本本身\n",
    "distances_test, neighbors_test = neigh.kneighbors(test_preds)\n",
    "\n",
    "distances_test, neighbors_test = distances_test.tolist(), neighbors_test.tolist()\n",
    "\n",
    "preds_str = []\n",
    "\n",
    "for filepath, distance, neighbour_ in zip(test_file_names, distances_test, neighbors_test):\n",
    "    sample_result = []\n",
    "    sample_classes = []\n",
    "    for d, n in zip(distance, neighbour_):\n",
    "        train_file = train_files[n].split(os.sep)[-1]\n",
    "        class_train = file_id_mapping[train_file]\n",
    "        sample_classes.append(class_train)\n",
    "        sample_result.append((class_train, d))\n",
    "\n",
    "    if \"new_whale\" not in sample_classes:\n",
    "        sample_result.append((\"new_whale\", 0.1))#new_whale有大概率出现，距离设置为0.1\n",
    "    sample_result.sort(key=lambda x: x[1])\n",
    "    sample_result = sample_result[:5] #取前五个距离最小的预测值\n",
    "    preds_str.append(\" \".join([x[0] for x in sample_result]))\n",
    "\n",
    "df = pd.DataFrame(preds_str, columns=[\"Id\"])\n",
    "df['Image'] = [x.split(os.sep)[-1] for x in test_file_names]\n",
    "sub_csv_path = \"sub_%s.csv\"%model_name\n",
    "sub_csv_path = os.path.join('./data/whale/siamese_augment', sub_csv_path)\n",
    "df.to_csv(sub_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
