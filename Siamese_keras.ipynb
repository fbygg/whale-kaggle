{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read me\n",
    "\n",
    "To run on multi-GPU server, please:\n",
    "[1]increase data_size to a larger number (say 10000):\n",
    "generate_image_pair_and_labels(X_imgs, labels_dataframe['labels'].tolist(), data_size=100)\n",
    "\n",
    "[2]increase image size if necessary (say 224):\n",
    "IMAGE_SIZE = 128\n",
    "\n",
    "[3]increase GPU numbers, 1 is default\n",
    "G = 1 #the number of GPU\n",
    "\n",
    "[4]increase epochs (say 300)\n",
    "n_epochs = 30\n",
    "\n",
    "[5]increae batch size if you have large GPU memory (say 50)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from math import floor, ceil, pi\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/whale/train_full/00022e1a.jpg', './data/whale/train_full/000466c4.jpg', './data/whale/train_full/00087b01.jpg', './data/whale/train_full/001296d5.jpg', './data/whale/train_full/0014cfdf.jpg', './data/whale/train_full/0025e8c2.jpg', './data/whale/train_full/0026a8ab.jpg', './data/whale/train_full/0031c258.jpg', './data/whale/train_full/0035632e.jpg', './data/whale/train_full/0037e7d3.jpg', './data/whale/train_full/00389cd7.jpg', './data/whale/train_full/0042dcc4.jpg', './data/whale/train_full/0042ea34.jpg', './data/whale/train_full/00467ae9.jpg', './data/whale/train_full/004a97f3.jpg', './data/whale/train_full/004c5fb9.jpg', './data/whale/train_full/005c57e7.jpg', './data/whale/train_full/006d0aaf.jpg', './data/whale/train_full/0078af23.jpg', './data/whale/train_full/007c3603.jpg']\n"
     ]
    }
   ],
   "source": [
    "def get_image_paths():\n",
    "    folder = './data/whale/train_full'\n",
    "    files = os.listdir(folder)\n",
    "    files.sort()\n",
    "    files = ['{}/{}'.format(folder, file) for file in files]\n",
    "    return files\n",
    "\n",
    "X_img_paths = get_image_paths()\n",
    "print(X_img_paths[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load whale ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00022e1a.jpg</td>\n",
       "      <td>w_e15442c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>w_1287fbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00087b01.jpg</td>\n",
       "      <td>w_da2efe0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001296d5.jpg</td>\n",
       "      <td>w_19e5482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014cfdf.jpg</td>\n",
       "      <td>w_f22f3e3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image         Id\n",
       "0  00022e1a.jpg  w_e15442c\n",
       "1  000466c4.jpg  w_1287fbc\n",
       "2  00087b01.jpg  w_da2efe0\n",
       "3  001296d5.jpg  w_19e5482\n",
       "4  0014cfdf.jpg  w_f22f3e3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_labels():\n",
    "    csv_file = './data/whale/train.csv'\n",
    "    data_labels = pd.read_csv(csv_file)\n",
    "    return data_labels\n",
    "\n",
    "data_labels = load_labels()\n",
    "data_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Id analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_labels['Id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select ids occur more than 4 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_subset_by_threshold(occurence=5):\n",
    "    value_statics = data_labels['Id'].value_counts()\n",
    "    value_cut = value_statics[value_statics >= occurence]\n",
    "    value_cut = value_cut[value_cut < 100] #remove the \"new whale\" type\n",
    "    return value_cut  #return type: pandas series\n",
    "\n",
    "label_subset = get_label_subset_by_threshold(occurence=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation: to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_augmentation(original_image):\n",
    "    #to do\n",
    "    \n",
    "    return original_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_include_subset(label, label_subset):\n",
    "    if label in label_subset.index:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image resize and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128\n",
    "\n",
    "def tf_resize_augment_images(X_img_file_paths):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, (None, None, 1))\n",
    "    tf_img = tf.image.resize_images(X, (IMAGE_SIZE, IMAGE_SIZE), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Each image is resized individually as different image may be of different size.\n",
    "        for index, file_path in enumerate(X_img_file_paths):\n",
    "            label = data_labels.iloc[index]['Id']\n",
    "            \n",
    "            if is_include_subset(label, label_subset):\n",
    "                img = mpimg.imread(file_path)\n",
    "                if len(img.shape) > 2:# convert to grayscale\n",
    "                    img = rgb2gray(img)\n",
    "                img = img.reshape(img.shape[0], img.shape[1], 1)\n",
    "                resized_img = sess.run(tf_img, feed_dict = {X: img})\n",
    "                X_data.append(data_augmentation(resized_img))\n",
    "                y_data.append(label)\n",
    "\n",
    "    X_data = np.array(X_data, dtype = np.float32) # Convert to numpy\n",
    "    return X_data, y_data\n",
    "\n",
    "X_imgs, y_data = tf_resize_augment_images(X_img_paths)\n",
    "print(X_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image nromalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_normalize(images):\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save processed images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./data/whale/save/resize.npy', X_imgs)\n",
    "labels_dataframe = pd.DataFrame({'labels':y_data})\n",
    "labels_dataframe.to_csv('./data/whale/save/labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w_1287fbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w_da2efe0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w_3d0bc7a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w_fd1cb9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w_ab6db0f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels\n",
       "0  w_1287fbc\n",
       "1  w_da2efe0\n",
       "2  w_3d0bc7a\n",
       "3  w_fd1cb9d\n",
       "4  w_ab6db0f"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imgs = np.load('./data/whale/save/resize.npy')\n",
    "labels_dataframe = pd.read_csv('./data/whale/save/labels.csv')\n",
    "labels_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate image pairs and labels(true or false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_image_pair_and_labels(images, labels, data_size=500):\n",
    "    size1 = data_size // 2 \n",
    "    size2 = data_size - size1\n",
    "    if size1 < size2 and np.random.rand() > 0.5:\n",
    "        size1, size2 = size2, size1\n",
    "    \n",
    "    X, y = [], []\n",
    "    k = 0\n",
    "    while k < size1:\n",
    "        idx1, idx2 = np.random.randint(0, len(labels), 2)\n",
    "        if idx1 != idx2 and labels[idx1] == labels[idx2]:\n",
    "            X.append(np.array([images[idx1], images[idx2]]))\n",
    "            y.append([1])\n",
    "            k += 1\n",
    "    k = 0\n",
    "    while k < size2:\n",
    "        idx1, idx2 = np.random.randint(0, len(labels), 2)\n",
    "        if labels[idx1] != labels[idx2]:\n",
    "            X.append(np.array([images[idx1], images[idx2]]))\n",
    "            y.append([0])\n",
    "            k += 1\n",
    "            \n",
    "    shuffled_idx = np.random.permutation(data_size)\n",
    "    return np.array(X)[shuffled_idx], np.array(y)[shuffled_idx]\n",
    "\n",
    "#select 100 pairs to tain siamese network, just for quick test\n",
    "image_pairs, y_labels = generate_image_pair_and_labels(X_imgs, labels_dataframe['labels'].tolist(), data_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.3\n",
    "image_pair_train = image_pairs[:int((1 - test_ratio) * len(y_labels))]\n",
    "y_labels_train = y_labels[:int((1 - test_ratio) * len(y_labels))]\n",
    "image_pair_test = image_pairs[int((1 - test_ratio) * len(y_labels)):]\n",
    "y_labels_test = y_labels[int((1 - test_ratio) * len(y_labels)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, subtract, merge, Dense, Flatten, MaxPooling2D, BatchNormalization, LeakyReLU, Activation, add\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "K.clear_session()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define residual network block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resNet_block(image1, image2, channel, strides):\n",
    "    conv1 = Conv2D(channel, kernel_size=(3, 3), strides=(strides, strides), kernel_initializer=\"he_normal\", padding='same')\n",
    "#   batch normalization parameters are not reused  \n",
    "    bn1 = BatchNormalization()\n",
    "    bn2 = BatchNormalization()\n",
    "    rl1 = Activation('relu') \n",
    "    conv2 = Conv2D(channel, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=\"he_normal\", padding='same')\n",
    "\n",
    "    #reuse weights & bias within block\n",
    "    net1 = conv2(rl1(bn1(conv1(image1))))\n",
    "    net2 = conv2(rl1(bn2(conv1(image2))))\n",
    "    \n",
    "    if strides > 1:\n",
    "        conv3 = Conv2D(channel, kernel_size=(3, 3), strides=(strides, strides), kernel_initializer=\"he_normal\", padding='same')\n",
    "        image1 = conv3(image1)\n",
    "        image2 = conv3(image2)\n",
    "        \n",
    "    net1 = add([image1, net1])\n",
    "    net2 = add([image2, net2])\n",
    "    bn3 = BatchNormalization()\n",
    "    bn4 = BatchNormalization()\n",
    "    rl2 = Activation('relu')\n",
    "    \n",
    "    return rl2(bn3(net1)), rl2(bn4(net2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define residual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_network(image1, image2):\n",
    "    conv1 = Conv2D(32, kernel_size=(7, 7), strides=(2, 2), kernel_initializer=\"he_normal\", padding='same')\n",
    "    bn1 = BatchNormalization()\n",
    "    bn2 = BatchNormalization()\n",
    "    rl1 = Activation('relu')  \n",
    "    mp1 = MaxPooling2D()\n",
    "    \n",
    "    net1, net2 = mp1(rl1(bn1(conv1(image1)))), mp1(rl1(bn2(conv1(image2))))\n",
    "    \n",
    "    net1, net2 = resNet_block(net1, net2, 32, 1)\n",
    "    net1, net2 = resNet_block(net1, net2, 32, 1)\n",
    "    net1, net2 = resNet_block(net1, net2, 32, 1)\n",
    "    net1, net2 = resNet_block(net1, net2, 64, 2)\n",
    "    net1, net2 = resNet_block(net1, net2, 64, 1)\n",
    "    net1, net2 = resNet_block(net1, net2, 64, 1)\n",
    "    net1, net2 = resNet_block(net1, net2, 128, 2)\n",
    "    net1, net2 = resNet_block(net1, net2, 128, 1)\n",
    "    net1, net2 = resNet_block(net1, net2, 128, 1)\n",
    "    \n",
    "    mp2 = MaxPooling2D()\n",
    "    flatten1 = Flatten()\n",
    "    \n",
    "    return flatten1(mp2(net1)), flatten1(mp2(net2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define siamese netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.00001\n",
    "input_shape = (2, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "inputs = Input(input_shape)\n",
    "G = 1 #the number of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "[INFO] training with 1 GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "def siamese_network(image_pairs):\n",
    "    # not support tf.ops in keras, fk!!!!\n",
    "#     image1, image2 = tf.unstack(image_pairs, axis=1)\n",
    "    image1 = Lambda(lambda x : x[:,0,:,:])(image_pairs)\n",
    "    image2 = Lambda(lambda x : x[:,1,:,:])(image_pairs)\n",
    "\n",
    "    embedding1, embedding2 = residual_network(image1, image2)\n",
    "    \n",
    "    #merge two encoded inputs with the l1 distance between them\n",
    "#     subtracted = subtract([embedding1, embedding2])\n",
    "#     both1 = K.abs(subtracted)\n",
    "#     print type(both1)\n",
    "    \n",
    "    L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "    both = merge([embedding1,embedding2], mode = L1_distance, output_shape=lambda x: x[0])\n",
    "    print type(both)\n",
    "    \n",
    "    prediction = Dense(1, activation='sigmoid', kernel_initializer='he_normal')(both)\n",
    "    \n",
    "    # check to see if we are compiling using just a single GPU\n",
    "    if G <= 1:\n",
    "        print(\"[INFO] training with 1 GPU...\")\n",
    "        siamese_net = Model(input=image_pairs, output=prediction)\n",
    "    # otherwise, we are compiling using multiple GPUs\n",
    "    else:\n",
    "        print(\"[INFO] training with {} GPUs...\".format(G))\n",
    "\n",
    "        # we'll store a copy of the model on *every* GPU and then combine\n",
    "        # the results from the gradient updates on the CPU\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            # initialize the model\n",
    "            siamese_net = Model(input=image_pairs, output=prediction)\n",
    "\n",
    "        # make the model parallel\n",
    "        siamese_net = multi_gpu_model(siamese_net, gpus=G)    \n",
    "    \n",
    "    optimizer = Adam(learning_rate)\n",
    "    siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return siamese_net\n",
    "\n",
    "siamese_net = siamese_network(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\tloss_train:0.855\tloss_test:0.814\tacc_train:60.00%\tacc_test:43.33%\n",
      "epoch:1\tloss_train:0.714\tloss_test:0.758\tacc_train:50.00%\tacc_test:46.67%\n",
      "epoch:2\tloss_train:0.572\tloss_test:0.709\tacc_train:50.00%\tacc_test:50.00%\n",
      "epoch:3\tloss_train:0.330\tloss_test:0.675\tacc_train:90.00%\tacc_test:56.67%\n",
      "epoch:4\tloss_train:0.668\tloss_test:0.651\tacc_train:50.00%\tacc_test:60.00%\n",
      "epoch:5\tloss_train:0.322\tloss_test:0.633\tacc_train:100.00%\tacc_test:60.00%\n",
      "epoch:6\tloss_train:0.512\tloss_test:0.622\tacc_train:70.00%\tacc_test:60.00%\n",
      "epoch:7\tloss_train:0.403\tloss_test:0.619\tacc_train:90.00%\tacc_test:63.33%\n",
      "epoch:8\tloss_train:0.406\tloss_test:0.616\tacc_train:90.00%\tacc_test:63.33%\n",
      "epoch:9\tloss_train:0.395\tloss_test:0.611\tacc_train:90.00%\tacc_test:63.33%\n",
      "epoch:10\tloss_train:0.543\tloss_test:0.610\tacc_train:60.00%\tacc_test:66.67%\n",
      "epoch:11\tloss_train:0.388\tloss_test:0.609\tacc_train:80.00%\tacc_test:66.67%\n",
      "epoch:12\tloss_train:0.311\tloss_test:0.607\tacc_train:100.00%\tacc_test:66.67%\n",
      "epoch:13\tloss_train:0.366\tloss_test:0.605\tacc_train:90.00%\tacc_test:66.67%\n",
      "epoch:14\tloss_train:0.326\tloss_test:0.602\tacc_train:90.00%\tacc_test:66.67%\n",
      "epoch:15\tloss_train:0.283\tloss_test:0.602\tacc_train:100.00%\tacc_test:66.67%\n",
      "epoch:16\tloss_train:0.238\tloss_test:0.604\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:17\tloss_train:0.241\tloss_test:0.604\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:18\tloss_train:0.308\tloss_test:0.602\tacc_train:90.00%\tacc_test:63.33%\n",
      "epoch:19\tloss_train:0.253\tloss_test:0.603\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:20\tloss_train:0.197\tloss_test:0.604\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:21\tloss_train:0.163\tloss_test:0.602\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:22\tloss_train:0.217\tloss_test:0.604\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:23\tloss_train:0.210\tloss_test:0.603\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:24\tloss_train:0.163\tloss_test:0.606\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:25\tloss_train:0.212\tloss_test:0.606\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:26\tloss_train:0.296\tloss_test:0.606\tacc_train:90.00%\tacc_test:63.33%\n",
      "epoch:27\tloss_train:0.122\tloss_test:0.608\tacc_train:100.00%\tacc_test:63.33%\n",
      "epoch:28\tloss_train:0.154\tloss_test:0.611\tacc_train:100.00%\tacc_test:60.00%\n",
      "epoch:29\tloss_train:0.172\tloss_test:0.608\tacc_train:100.00%\tacc_test:63.33%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 10\n",
    "n_batches = len(y_labels_train) // batch_size\n",
    "\n",
    "for epoch in range(n_epochs):    \n",
    "    idx = np.random.permutation(len(y_labels_train))\n",
    "    X_batches = np.array_split(image_pair_train[idx], n_batches)\n",
    "    y_batches = np.array_split(y_labels_train[idx], n_batches)\n",
    "\n",
    "    for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "        loss_train, acc_train = siamese_net.train_on_batch(X_batch,y_batch)\n",
    "\n",
    "    loss_test, acc_test = siamese_net.evaluate(x=image_pair_test, y=y_labels_test, batch_size=10, verbose=0)\n",
    "    \n",
    "    print \"epoch:{}\\tloss_train:{:.3f}\\tloss_test:{:.3f}\\tacc_train:{:.2f}%\\tacc_test:{:.2f}%\".format(\n",
    "        epoch, loss_train, loss_test, acc_train*100, acc_test*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
