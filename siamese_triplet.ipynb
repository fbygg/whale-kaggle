{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key notes\n",
    "\n",
    "1.主框架模型时siamese + triplet loss, 求每个image的embedding（长度为50的vector）时用了resNet50模型\n",
    "\n",
    "2.triplet loss使用了Bayesian Personalized Ranking loss\n",
    "\n",
    "3.预处理只做了resize to (256, 256)和convert to RGB, 以及小概率(10%)的fliplr，没有做augment\n",
    "\n",
    "4.挑选triplet的时候没有刻意去挑选（像andrew ng的video和那篇paper里面说的那样，需要刻意去挑选，以提升性能。\n",
    "\n",
    "5.在生产训练batch的时候，用了generator + yield，所有batch的生成都是on the fly，大大减少了memory的消耗\n",
    "\n",
    "6.模型训练完之后，将所有的train images和test images的embedding都计算出来，在embedding（长度只有50）的基础上再做test images的预测，这样大大提升了预测速度\n",
    "\n",
    "7.预测用了knn算法，最后选取最近的5个class id\n",
    "\n",
    "8.因为new whale有大概率出现（9850个train images出现了810次），这里强制把new whale在knn的distance设置为0.1（有待商榷）\n",
    "\n",
    "总结：最粗糙暴力的方法，最后的MAP有0.42左右，排名还挺高，可以考虑在这个基础上优化。\n",
    "\n",
    "优化方向：\n",
    "\n",
    "1.preprocessing\n",
    "\n",
    "2.augmentation\n",
    "\n",
    "3.the way to choose triplet\n",
    "\n",
    "4.the knn default distance for new_whale 0.1 ??\n",
    "\n",
    "5.make use of the test images, for example autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#part of the code is from https://github.com/maciejkula/triplet_recommendations_keras\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, GlobalMaxPooling2D\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.neighbors import NearestNeighbors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sample_gen(object):\n",
    "    def __init__(self, file_class_mapping, other_class = \"new_whale\"):\n",
    "        self.file_class_mapping= file_class_mapping\n",
    "        self.class_to_list_files = defaultdict(list)\n",
    "        self.list_other_class = []\n",
    "        self.list_all_files = list(file_class_mapping.keys())\n",
    "        self.range_all_files = list(range(len(self.list_all_files)))\n",
    "\n",
    "        for file, class_ in file_class_mapping.items():\n",
    "            if class_ == other_class:\n",
    "                self.list_other_class.append(file)\n",
    "            else:\n",
    "                self.class_to_list_files[class_].append(file)\n",
    "\n",
    "#       注意这里的class id有重复\n",
    "        self.list_classes = list(set(self.file_class_mapping.values()))\n",
    "        self.range_list_classes= range(len(self.list_classes))\n",
    "#       每个class（Id）的比重，相当于直方图  \n",
    "        self.class_weight = np.array([len(self.class_to_list_files[class_]) for class_ in self.list_classes]) * 1.0\n",
    "#         self.class_weight = self.class_weight/np.sum(self.class_weight)\n",
    "        \n",
    "        self.class_weight /= self.class_weight.sum()\n",
    "        print \"sum=\", self.class_weight.sum()\n",
    "\n",
    "#   这个函数只是返回一个triplet样例\n",
    "    def get_sample(self):\n",
    "#       按class id比重抽取一个样本\n",
    "        class_idx = np.random.choice(self.range_list_classes, 1, p=self.class_weight)[0]\n",
    "#       对这种class id的，抽取两个样本images (如果某个class只有一个样本，那么返回的是两个一样的image)\n",
    "        examples_class_idx = np.random.choice(range(len(self.class_to_list_files[self.list_classes[class_idx]])), 2)\n",
    "#       注意这两个样本属于同一个class\n",
    "        positive_example_1, positive_example_2 = \\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[0]],\\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[1]]\n",
    "\n",
    "#       提取一个跟positive_example_1不同class的样本\n",
    "        negative_example = None\n",
    "        while negative_example is None or self.file_class_mapping[negative_example] == \\\n",
    "                self.file_class_mapping[positive_example_1]:\n",
    "            negative_example_idx = np.random.choice(self.range_all_files, 1)[0]\n",
    "            negative_example = self.list_all_files[negative_example_idx]\n",
    "        return positive_example_1, negative_example, positive_example_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "input_shape = (256, 256)\n",
    "base_path = \"./data/whale/train_full/\"\n",
    "\n",
    "# 就是返回了y_pred的平均值\n",
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "# Bayesian Personalized Ranking loss\n",
    "def bpr_triplet_loss(X):\n",
    "\n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "    # BPR loss\n",
    "    loss = 1.0 - K.sigmoid(\n",
    "        K.sum(user_latent * positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(user_latent * negative_item_latent, axis=-1, keepdims=True))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_base_model():\n",
    "    latent_dim = 50\n",
    "#   include_top：whether to include the fully-connected layer at the top of the network.\n",
    "    base_model = ResNet50(weights='imagenet',include_top=False) # use weights='imagenet' locally\n",
    "\n",
    "    # for layer in base_model.layers:\n",
    "    #     layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(latent_dim)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_1)\n",
    "#   相当于对这50长度的vector，每个元素取平方，方便后面的距离计算\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model\n",
    "\n",
    "def build_model():\n",
    "    base_model = get_base_model()\n",
    "#   input结构变成(256, 256, 3)\n",
    "    positive_example_1 = Input(input_shape+(3,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(3,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(3,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "#   用triplet loss的方式对三个embedding进行merge,输出是一个sigmoid\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_name = \"triplet_model\"\n",
    "\n",
    "file_path = model_name + \"weights.best.hdf5\"\n",
    "\n",
    "\n",
    "\n",
    "def build_inference_model(weight_path=file_path):\n",
    "    base_model = get_base_model()\n",
    "\n",
    "    positive_example_1 = Input(input_shape+(3,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(3,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(3,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "#   导入前面训练出来的权重\n",
    "    model.load_weights(weight_path)\n",
    "\n",
    "#   base model只包含了把input转为embedding的过程，没有包含后面的triplet loss部分\n",
    "    inference_model = Model(base_model.get_input_at(0), output=base_model.get_output_at(0))\n",
    "    inference_model.compile(loss=\"mse\", optimizer=Adam(0.000001))\n",
    "    print(inference_model.summary())\n",
    "\n",
    "    return inference_model\n",
    "\n",
    "def read_and_resize(filepath):\n",
    "#   这里不是用的grayscale，而是转成RGB了\n",
    "    im = Image.open((filepath)).convert('RGB')\n",
    "    im = im.resize(input_shape)\n",
    "#   im的shape变成（256， 256， 3）\n",
    "    im_array = np.array(im, dtype=\"uint8\")[..., ::-1] #这个是对RGB进行逆序？？\n",
    "#   转换成float类型\n",
    "    return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "\n",
    "# 进行小概率的augment\n",
    "def augment(im_array):\n",
    "    if np.random.uniform(0, 1) > 0.9:\n",
    "#       fliplr只对第1维度column进行flip\n",
    "        im_array = np.fliplr(im_array)\n",
    "    return im_array\n",
    "\n",
    "# 这个函数返回一个generator\n",
    "def gen(triplet_gen):\n",
    "    while True:\n",
    "        list_positive_examples_1 = []\n",
    "        list_negative_examples = []\n",
    "        list_positive_examples_2 = []\n",
    "\n",
    "#       会有重复抽样\n",
    "        for i in range(batch_size):\n",
    "            positive_example_1, negative_example, positive_example_2 = triplet_gen.get_sample()\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = read_and_resize(base_path+positive_example_1), \\\n",
    "                                                                       read_and_resize(base_path+negative_example), \\\n",
    "                                                                       read_and_resize(base_path+positive_example_2)\n",
    "#           这个增强并没有增加训练样本数，而是替换了原样本\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = augment(positive_example_1_img), \\\n",
    "                                                                                   augment(negative_example_img), \\\n",
    "                                                                                   augment(positive_example_2_img)\n",
    "\n",
    "            list_positive_examples_1.append(positive_example_1_img)\n",
    "            list_negative_examples.append(negative_example_img)\n",
    "            list_positive_examples_2.append(positive_example_2_img)\n",
    "\n",
    "        list_positive_examples_1 = np.array(list_positive_examples_1)\n",
    "        list_negative_examples = np.array(list_negative_examples)\n",
    "        list_positive_examples_2 = np.array(list_positive_examples_2)\n",
    "        \n",
    "#       利用yield，返回一个generator, 并且call on the fly (通过yield + while True)，节省内存\n",
    "#       注意配合model.fit_generator使用的generator返回值必须是（input, target），所以后面的np.ones(batch_size)相当于target (即label)\n",
    "#       只不过在这个模型里面这个target没有被用上而已\n",
    "#       最后注意每次yield返回一个batch的samples\n",
    "        yield [list_positive_examples_1, list_negative_examples, list_positive_examples_2], np.ones(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum= 1.0\n",
      "sum= 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv('./data/whale/train.csv')\n",
    "train, test = train_test_split(data, test_size=0.3, shuffle=True, random_state=1337)\n",
    "#把image作为key，id作为value\n",
    "file_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\n",
    "file_id_mapping_test = {k: v for k, v in zip(test.Image.values, test.Id.values)}\n",
    "train_gen = sample_gen(file_id_mapping_train)\n",
    "test_gen = sample_gen(file_id_mapping_test)\n",
    "\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:98: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:102: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"lo..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "positive_example_1 (InputLayer) (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_example (InputLayer)   (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_example_2 (InputLayer) (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Model)              (None, 50)           23690162    positive_example_1[0][0]         \n",
      "                                                                 negative_example[0][0]           \n",
      "                                                                 positive_example_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "loss (Merge)                    (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "                                                                 base_model[3][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,690,162\n",
      "Trainable params: 23,637,042\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      " - 264s - loss: 0.4616 - val_loss: 0.3795\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37946, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 2/300\n",
      " - 241s - loss: 0.4524 - val_loss: 0.3674\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37946 to 0.36743, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 3/300\n",
      " - 241s - loss: 0.4463 - val_loss: 0.3595\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36743 to 0.35951, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 4/300\n",
      " - 241s - loss: 0.4362 - val_loss: 0.3362\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35951 to 0.33618, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 5/300\n",
      " - 241s - loss: 0.4241 - val_loss: 0.3332\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33618 to 0.33320, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 6/300\n",
      " - 241s - loss: 0.4136 - val_loss: 0.3262\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33320 to 0.32624, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 7/300\n",
      " - 241s - loss: 0.4066 - val_loss: 0.3170\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.32624 to 0.31697, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 8/300\n",
      " - 241s - loss: 0.3955 - val_loss: 0.3133\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.31697 to 0.31327, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 9/300\n",
      " - 241s - loss: 0.3852 - val_loss: 0.3107\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31327 to 0.31066, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 10/300\n",
      " - 241s - loss: 0.3787 - val_loss: 0.3127\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31066\n",
      "Epoch 11/300\n",
      " - 240s - loss: 0.3745 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31066\n",
      "Epoch 12/300\n",
      " - 241s - loss: 0.3689 - val_loss: 0.3083\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31066 to 0.30833, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 13/300\n",
      " - 241s - loss: 0.3648 - val_loss: 0.3129\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.30833\n",
      "Epoch 14/300\n",
      " - 241s - loss: 0.3610 - val_loss: 0.3035\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.30833 to 0.30351, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 15/300\n",
      " - 241s - loss: 0.3563 - val_loss: 0.3125\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.30351\n",
      "Epoch 16/300\n",
      " - 241s - loss: 0.3488 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.30351 to 0.28907, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 17/300\n",
      " - 241s - loss: 0.3509 - val_loss: 0.3070\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.28907\n",
      "Epoch 18/300\n",
      " - 241s - loss: 0.3467 - val_loss: 0.3068\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.28907\n",
      "Epoch 19/300\n",
      " - 241s - loss: 0.3378 - val_loss: 0.3038\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.28907\n",
      "Epoch 20/300\n",
      " - 241s - loss: 0.3381 - val_loss: 0.3230\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.28907\n",
      "Epoch 21/300\n",
      " - 241s - loss: 0.3424 - val_loss: 0.3046\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.28907\n",
      "Epoch 22/300\n",
      " - 241s - loss: 0.3372 - val_loss: 0.3089\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.28907\n",
      "Epoch 23/300\n",
      " - 241s - loss: 0.3362 - val_loss: 0.3046\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.28907\n",
      "Epoch 24/300\n",
      " - 241s - loss: 0.3375 - val_loss: 0.3140\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.28907\n",
      "Epoch 25/300\n",
      " - 241s - loss: 0.3342 - val_loss: 0.3041\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.28907\n",
      "Epoch 26/300\n",
      " - 241s - loss: 0.3350 - val_loss: 0.3216\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.28907\n",
      "Epoch 27/300\n",
      " - 241s - loss: 0.3307 - val_loss: 0.3061\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.28907\n",
      "Epoch 28/300\n",
      " - 241s - loss: 0.3273 - val_loss: 0.3052\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.28907\n",
      "Epoch 29/300\n",
      " - 241s - loss: 0.3328 - val_loss: 0.3092\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.28907\n",
      "Epoch 30/300\n",
      " - 241s - loss: 0.3267 - val_loss: 0.2931\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.28907\n",
      "Epoch 31/300\n",
      " - 241s - loss: 0.3294 - val_loss: 0.2976\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.28907\n",
      "Epoch 32/300\n",
      " - 241s - loss: 0.3280 - val_loss: 0.2989\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.28907\n",
      "Epoch 33/300\n",
      " - 241s - loss: 0.3260 - val_loss: 0.3035\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.28907\n",
      "Epoch 34/300\n",
      " - 241s - loss: 0.3255 - val_loss: 0.3002\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.28907\n",
      "Epoch 35/300\n",
      " - 241s - loss: 0.3259 - val_loss: 0.3053\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.28907\n",
      "Epoch 36/300\n",
      " - 241s - loss: 0.3231 - val_loss: 0.3012\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.28907\n",
      "Epoch 37/300\n",
      " - 241s - loss: 0.3225 - val_loss: 0.3010\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.28907\n",
      "Epoch 38/300\n",
      " - 241s - loss: 0.3218 - val_loss: 0.2943\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.28907\n",
      "Epoch 39/300\n",
      " - 241s - loss: 0.3236 - val_loss: 0.2892\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.28907\n",
      "Epoch 40/300\n",
      " - 241s - loss: 0.3209 - val_loss: 0.3024\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.28907\n",
      "Epoch 41/300\n",
      " - 241s - loss: 0.3198 - val_loss: 0.2864\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.28907 to 0.28639, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 42/300\n",
      " - 241s - loss: 0.3183 - val_loss: 0.3061\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.28639\n",
      "Epoch 43/300\n",
      " - 241s - loss: 0.3170 - val_loss: 0.3041\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.28639\n",
      "Epoch 44/300\n",
      " - 241s - loss: 0.3158 - val_loss: 0.3047\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.28639\n",
      "Epoch 45/300\n",
      " - 241s - loss: 0.3187 - val_loss: 0.3084\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.28639\n",
      "Epoch 46/300\n",
      " - 241s - loss: 0.3172 - val_loss: 0.2833\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.28639 to 0.28325, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 47/300\n",
      " - 241s - loss: 0.3175 - val_loss: 0.3043\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.28325\n",
      "Epoch 48/300\n",
      " - 241s - loss: 0.3177 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.28325\n",
      "Epoch 49/300\n",
      " - 241s - loss: 0.3179 - val_loss: 0.2930\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.28325\n",
      "Epoch 50/300\n",
      " - 241s - loss: 0.3154 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.28325\n",
      "Epoch 51/300\n",
      " - 241s - loss: 0.3170 - val_loss: 0.2861\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.28325\n",
      "Epoch 52/300\n",
      " - 241s - loss: 0.3127 - val_loss: 0.2950\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.28325\n",
      "Epoch 53/300\n",
      " - 241s - loss: 0.3150 - val_loss: 0.2903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00053: val_loss did not improve from 0.28325\n",
      "Epoch 54/300\n",
      " - 241s - loss: 0.3162 - val_loss: 0.2917\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.28325\n",
      "Epoch 55/300\n",
      " - 241s - loss: 0.3144 - val_loss: 0.3013\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.28325\n",
      "Epoch 56/300\n",
      " - 241s - loss: 0.3122 - val_loss: 0.3069\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.28325\n",
      "Epoch 57/300\n",
      " - 241s - loss: 0.3072 - val_loss: 0.2985\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.28325\n",
      "Epoch 58/300\n",
      " - 241s - loss: 0.3091 - val_loss: 0.2962\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.28325\n",
      "Epoch 59/300\n",
      " - 241s - loss: 0.3092 - val_loss: 0.2844\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.28325\n",
      "Epoch 60/300\n",
      " - 241s - loss: 0.3084 - val_loss: 0.2900\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.28325\n",
      "Epoch 61/300\n",
      " - 241s - loss: 0.3083 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.28325\n",
      "Epoch 62/300\n",
      " - 241s - loss: 0.3061 - val_loss: 0.3096\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.28325\n",
      "Epoch 63/300\n",
      " - 241s - loss: 0.3090 - val_loss: 0.2989\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.28325\n",
      "Epoch 64/300\n",
      " - 241s - loss: 0.3099 - val_loss: 0.2926\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.28325\n",
      "Epoch 65/300\n",
      " - 241s - loss: 0.3046 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.28325\n",
      "Epoch 66/300\n",
      " - 241s - loss: 0.3067 - val_loss: 0.2959\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.28325\n",
      "Epoch 67/300\n",
      " - 241s - loss: 0.3105 - val_loss: 0.3012\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.28325\n",
      "Epoch 68/300\n",
      " - 241s - loss: 0.3082 - val_loss: 0.2995\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.28325\n",
      "Epoch 69/300\n",
      " - 241s - loss: 0.3062 - val_loss: 0.3068\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.28325\n",
      "Epoch 70/300\n",
      " - 241s - loss: 0.3043 - val_loss: 0.2842\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.28325\n",
      "Epoch 71/300\n",
      " - 241s - loss: 0.3060 - val_loss: 0.2814\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.28325 to 0.28141, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 72/300\n",
      " - 241s - loss: 0.3062 - val_loss: 0.3087\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.28141\n",
      "Epoch 73/300\n",
      " - 241s - loss: 0.3065 - val_loss: 0.2907\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.28141\n",
      "Epoch 74/300\n",
      " - 241s - loss: 0.3078 - val_loss: 0.2772\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.28141 to 0.27719, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 75/300\n",
      " - 241s - loss: 0.3052 - val_loss: 0.2979\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.27719\n",
      "Epoch 76/300\n",
      " - 241s - loss: 0.3058 - val_loss: 0.3024\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.27719\n",
      "Epoch 77/300\n",
      " - 241s - loss: 0.3029 - val_loss: 0.2904\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.27719\n",
      "Epoch 78/300\n",
      " - 241s - loss: 0.3080 - val_loss: 0.2961\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.27719\n",
      "Epoch 79/300\n",
      " - 241s - loss: 0.3052 - val_loss: 0.2859\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.27719\n",
      "Epoch 80/300\n",
      " - 241s - loss: 0.3023 - val_loss: 0.2856\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.27719\n",
      "Epoch 81/300\n",
      " - 241s - loss: 0.3054 - val_loss: 0.3011\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.27719\n",
      "Epoch 82/300\n",
      " - 241s - loss: 0.3099 - val_loss: 0.3053\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.27719\n",
      "Epoch 83/300\n",
      " - 241s - loss: 0.3064 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.27719\n",
      "Epoch 84/300\n",
      " - 241s - loss: 0.3048 - val_loss: 0.2957\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.27719\n",
      "Epoch 85/300\n",
      " - 241s - loss: 0.3032 - val_loss: 0.2886\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.27719\n",
      "Epoch 86/300\n",
      " - 241s - loss: 0.3048 - val_loss: 0.2801\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.27719\n",
      "Epoch 87/300\n",
      " - 241s - loss: 0.3029 - val_loss: 0.2963\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.27719\n",
      "Epoch 88/300\n",
      " - 241s - loss: 0.3037 - val_loss: 0.2993\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.27719\n",
      "Epoch 89/300\n",
      " - 241s - loss: 0.3075 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.27719\n",
      "Epoch 90/300\n",
      " - 241s - loss: 0.3057 - val_loss: 0.3044\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.27719\n",
      "Epoch 91/300\n",
      " - 241s - loss: 0.3013 - val_loss: 0.2992\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.27719\n",
      "Epoch 92/300\n",
      " - 241s - loss: 0.3030 - val_loss: 0.2972\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.27719\n",
      "Epoch 93/300\n",
      " - 241s - loss: 0.2995 - val_loss: 0.2893\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.27719\n",
      "Epoch 94/300\n",
      " - 241s - loss: 0.3055 - val_loss: 0.2873\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.27719\n",
      "Epoch 95/300\n",
      " - 241s - loss: 0.3033 - val_loss: 0.2994\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.27719\n",
      "Epoch 96/300\n",
      " - 241s - loss: 0.3011 - val_loss: 0.2927\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.27719\n",
      "Epoch 97/300\n",
      " - 241s - loss: 0.3053 - val_loss: 0.2954\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.27719\n",
      "Epoch 98/300\n",
      " - 241s - loss: 0.3010 - val_loss: 0.2946\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.27719\n",
      "Epoch 99/300\n",
      " - 241s - loss: 0.3002 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.27719\n",
      "Epoch 100/300\n",
      " - 241s - loss: 0.3009 - val_loss: 0.3030\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.27719\n",
      "Epoch 101/300\n",
      " - 241s - loss: 0.3026 - val_loss: 0.2872\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.27719\n",
      "Epoch 102/300\n",
      " - 241s - loss: 0.3015 - val_loss: 0.2876\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.27719\n",
      "Epoch 103/300\n",
      " - 241s - loss: 0.2977 - val_loss: 0.2927\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.27719\n",
      "Epoch 104/300\n",
      " - 241s - loss: 0.2994 - val_loss: 0.3018\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.27719\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test triplets\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "\n",
    "#model.load_weights(file_path)\n",
    "\n",
    "# 根据monitor的值即loss，保存loss最小(min)时的model (best model)\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "\n",
    "callbacks_list = [checkpoint, early]  # early\n",
    "\n",
    "# Trains the model on data generated batch-by-batch by a Python generator\n",
    "# 这种模式，generate bath on the fly，可以节省很多memory，因而可以使用更大的batch size\n",
    "history = model.fit_generator(gen(train_gen), validation_data=gen(test_gen), epochs=num_epochs, verbose=2, workers=1, use_multiprocessing=False,\n",
    "                              callbacks=callbacks_list, steps_per_epoch=500, validation_steps=50)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:131: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:135: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"lo..., inputs=[<tf.Tenso...)`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:142: UserWarning: Update your `Model` call to the Keras 2 API: `Model(Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 6 0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 2 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 2 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 2 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 5 0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 5 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 5 0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 5 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 1 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 1 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 1 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 1 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 1 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 2 0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 2 0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, None, 2 0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, None, None, 2 0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           102450      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50)           0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,690,162\n",
      "Trainable params: 23,637,042\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = \"triplet_loss\"\n",
    "def data_generator(fpaths, batch=16):\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        img = read_and_resize(path)\n",
    "        imgs.append(img)\n",
    "#       获取image的名字\n",
    "        fnames.append(os.path.basename(path))\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "#           每次yield返回一个batch的samples\n",
    "            yield fnames, imgs\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        yield fnames, imgs\n",
    "    raise StopIteration()\n",
    "\n",
    "data = pd.read_csv('./data/whale/train.csv')\n",
    "\n",
    "file_id_mapping = {k: v for k, v in zip(data.Image.values, data.Id.values)}\n",
    "\n",
    "inference_model = build_inference_model()\n",
    "\n",
    "# 文件名匹配，返回一个list包含所有这个后缀的文件path\n",
    "train_files = glob.glob(\"./data/whale/train_full/*.jpg\")\n",
    "test_files = glob.glob(\"./data/whale/test/*.jpg\")\n",
    "\n",
    "train_preds = []\n",
    "train_file_names = []\n",
    "i = 1\n",
    "# 每个imgs里面包含的是一个batch的samples\n",
    "for fnames, imgs in data_generator(train_files, batch=32):\n",
    "#     print(i*32/len(train_files)*100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "#   将一个batch的images转换成embeddings，然后转成list\n",
    "    predicts = predicts.tolist()\n",
    "    train_preds += predicts\n",
    "    train_file_names += fnames\n",
    "\n",
    "#  得到了所有train images的embeddings\n",
    "train_preds = np.array(train_preds)\n",
    "\n",
    "test_preds = []\n",
    "test_file_names = []\n",
    "i = 1\n",
    "for fnames, imgs in data_generator(test_files, batch=32):\n",
    "#     print(i * 32 / len(test_files) * 100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "    predicts = predicts.tolist()\n",
    "    test_preds += predicts\n",
    "    test_file_names += fnames\n",
    "\n",
    "#  得到了所有test images的embeddings\n",
    "test_preds = np.array(test_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这里用欧式距离判断class id，并且选取了6个neighbors\n",
    "neigh = NearestNeighbors(n_neighbors=6)\n",
    "neigh.fit(train_preds)\n",
    "#distances, neighbors = neigh.kneighbors(train_preds)\n",
    "\n",
    "#print(distances, neighbors)\n",
    "\n",
    "# 对每个test样本，返回最近的六个embeddings,注意neighbors_test是train_preds里面样本的Index，而非样本本身\n",
    "distances_test, neighbors_test = neigh.kneighbors(test_preds)\n",
    "\n",
    "distances_test, neighbors_test = distances_test.tolist(), neighbors_test.tolist()\n",
    "\n",
    "preds_str = []\n",
    "\n",
    "for filepath, distance, neighbour_ in zip(test_file_names, distances_test, neighbors_test):\n",
    "    sample_result = []\n",
    "    sample_classes = []\n",
    "    for d, n in zip(distance, neighbour_):\n",
    "        train_file = train_files[n].split(os.sep)[-1]\n",
    "        class_train = file_id_mapping[train_file]\n",
    "        sample_classes.append(class_train)\n",
    "        sample_result.append((class_train, d))\n",
    "\n",
    "    if \"new_whale\" not in sample_classes:\n",
    "        sample_result.append((\"new_whale\", 0.05))#new_whale有大概率出现，距离设置为0.1\n",
    "    sample_result.sort(key=lambda x: x[1])\n",
    "    sample_result = sample_result[:5] #取前五个距离最小的预测值\n",
    "    preds_str.append(\" \".join([x[0] for x in sample_result]))\n",
    "\n",
    "df = pd.DataFrame(preds_str, columns=[\"Id\"])\n",
    "df['Image'] = [x.split(os.sep)[-1] for x in test_file_names]\n",
    "df.to_csv(\"sub_%s.csv\"%model_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08126209 0.08126209 0.08186337 0.08216192 0.08413878 0.08443262]\n",
      " [0.10770522 0.10879348 0.11002699 0.118119   0.11852136 0.12149963]\n",
      " [0.         0.17586181 0.17881008 0.1869628  0.19458691 0.19706372]\n",
      " [0.18991647 0.19711524 0.19720327 0.19731364 0.19800723 0.20047218]\n",
      " [0.17595036 0.17924069 0.18244697 0.18247241 0.18358763 0.1843859 ]\n",
      " [0.05163546 0.05667249 0.05690539 0.05814614 0.05902657 0.05960685]\n",
      " [0.17996753 0.18226758 0.18281613 0.18805499 0.19108193 0.19247563]\n",
      " [0.09034755 0.09096052 0.09157771 0.09173478 0.0926957  0.09283236]\n",
      " [0.12068342 0.12173704 0.12741168 0.12850561 0.1286524  0.1286524 ]\n",
      " [0.09132574 0.09284253 0.09408153 0.09426448 0.09444214 0.09456885]]\n"
     ]
    }
   ],
   "source": [
    "# check the distance range\n",
    "# 如何选择new_whale对应的距离值？  why 0.1 ？？？？\n",
    "test_preds_parts = test_preds[:10]\n",
    "distances_test, neighbors_test = neigh.kneighbors(test_preds_parts)\n",
    "print distances_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
